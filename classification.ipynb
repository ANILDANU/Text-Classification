{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC News article classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/ANIL DANU/Documents/bbc-text.csv\")   #provided by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()    #this will display the first five rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts() #provided by pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training data : 1780\n",
      "size of the test data : 445\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * .8)                     #define training and testing data size\n",
    "print('Size of the training data :',train_size)\n",
    "print('size of the test data :',len(data)-train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_size):                #spliting the data into train and test data\n",
    "    train = data[:train_size]\n",
    "    test = data[train_size:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat, test_cat = train_test_split(data['category'], train_size)\n",
    "train_text, test_text = train_test_split(data['text'], train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000       \n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)  #This class vectorize the text corpus\n",
    "\n",
    "#num_words: the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n",
    "#char_level: if True, every character will be treated as a token.\n",
    "tokenize.fit_on_texts(train_text) \n",
    "word_index = tokenize.word_index\n",
    "#print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 1000)\n"
     ]
    }
   ],
   "source": [
    "x_train = tokenize.texts_to_matrix(train_text,mode='count')    #converting text the matrix   mode:binary,count,freq,tfidf\n",
    "x_test = tokenize.texts_to_matrix(test_text,mode='count')\n",
    "print(x_train.shape)\n",
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "[4 0 3 ... 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()            #Encode target labels with value between 0 and n_classes-1.\n",
    "encoder.fit(train_cat)\n",
    "print(list(encoder.classes_))\n",
    "y_train = encoder.transform(train_cat)  #transfrom training data to corresponding categorical values\n",
    "y_test = encoder.transform(test_cat)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)  #transfrom y_train from categorical to binary representation\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1780, 1000)\n",
      "x_test shape: (445, 1000)\n",
      "y_train shape: (1780, 5)\n",
      "y_test shape: (445, 5)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)    #checking the dimension of different matrix\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16   # number of training examples utilized in one iteration\n",
    "epochs = 2   #The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work\n",
    "#through the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to \n",
    "#update the internal model parameters.\n",
    "drop_ratio = 0.5   #it is used to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()   #it is simply stack of layer with single input and single output layer\n",
    "model.add(layers.Dense(512, input_shape=(max_words,)))    #512 is the dimention\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(drop_ratio))\n",
    "model.add(layers.Dense(num_classes))   #output layer\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#loss: mse,binarycrossentropy\n",
    "#model: adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "101/101 [==============================] - 1s 9ms/step - loss: 0.6324 - accuracy: 0.7996 - val_loss: 0.1322 - val_accuracy: 0.9607\n",
      "Epoch 2/2\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.9526 - val_loss: 0.1082 - val_accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9371\n",
      "Test loss: 0.15797629952430725\n",
      "Test accuracy: 0.9370786547660828\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hobbit picture  four years away  lord of the rings ...\n",
      "Actual label:entertainment\n",
      "Predicted label: entertainment\n",
      "\n",
      "game firm holds  cast  auditions video game firm b ...\n",
      "Actual label:tech\n",
      "Predicted label: tech\n",
      "\n",
      "clarke plans migrant point scheme anyone planning  ...\n",
      "Actual label:politics\n",
      "Predicted label: politics\n",
      "\n",
      "radcliffe will compete in london paula radcliffe w ...\n",
      "Actual label:sport\n",
      "Predicted label: sport\n",
      "\n",
      "serena becomes world number two serena williams ha ...\n",
      "Actual label:sport\n",
      "Predicted label: sport\n",
      "\n",
      "ultimate game  award for doom 3 sci-fi shooter doo ...\n",
      "Actual label:tech\n",
      "Predicted label: tech\n",
      "\n",
      "algeria hit by further gas riots algeria suffered  ...\n",
      "Actual label:business\n",
      "Predicted label: business\n",
      "\n",
      "fast lifts rise into record books two high-speed l ...\n",
      "Actual label:tech\n",
      "Predicted label: entertainment\n",
      "\n",
      "muslim group attacks tv drama 24 a british muslim  ...\n",
      "Actual label:entertainment\n",
      "Predicted label: entertainment\n",
      "\n",
      "us tv special for tsunami relief a us television n ...\n",
      "Actual label:entertainment\n",
      "Predicted label: entertainment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_labels = encoder.classes_ \n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(test_text.iloc[i][:50], \"...\")\n",
    "    print('Actual label:' + test_cat.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
